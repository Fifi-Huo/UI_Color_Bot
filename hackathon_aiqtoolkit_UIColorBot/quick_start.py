#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬ - ç›´æ¥ä½¿ç”¨FastAPIå¯åŠ¨æœåŠ¡
"""

import asyncio
import json
import logging
import os
import tempfile
import uuid
from pathlib import Path
from typing import Dict, Any, List, Optional
import base64
import io

import httpx
import uvicorn
import yaml
import requests
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from sklearn.cluster import KMeans
from dotenv import load_dotenv
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import uvicorn
from pathlib import Path
from config_loader import load_config_with_env
from bailian_client import BailianClient
from color_utils import ColorUtils
from nim_client import NIMClient, EnhancedColorAnalyzer

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_env():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    from dotenv import load_dotenv
    env_path = Path(__file__).parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        # æ‰“å°åŠ è½½çš„ç¯å¢ƒå˜é‡ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
        for key in ['BAILIAN_API_KEY', 'DASHSCOPE_API_KEY', 'TAVILY_API_KEY']:
            value = os.getenv(key)
            if value:
                print(f"âœ… åŠ è½½ç¯å¢ƒå˜é‡: {key} = {value[:10]}...")
        print("âœ… ç¯å¢ƒå˜é‡åŠ è½½å®Œæˆ")
    else:
        print("âŒ æœªæ‰¾åˆ° .env æ–‡ä»¶")

def create_simple_app():
    """åˆ›å»ºç®€å•çš„FastAPIåº”ç”¨"""
    app = FastAPI(
        title="UI Color Bot API",
        description="åŸºäºç™¾ç‚¼APIçš„UIé¢œè‰²åŠ©æ‰‹",
        version="1.0.0"
    )
    
    # æ·»åŠ CORSä¸­é—´ä»¶æ”¯æŒå‰ç«¯è®¿é—®
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    @app.get("/")
    async def root():
        return {"message": "UI Color Bot API è¿è¡Œä¸­", "status": "ok"}
    
    @app.get("/health")
    async def health():
        return {"status": "healthy", "api_configured": bool(os.getenv("BAILIAN_API_KEY"))}
    
    @app.post("/color/analyze")
    async def analyze_colors(request: dict):
        """é¢œè‰²åˆ†ææ¥å£ - é›†æˆNVIDIA NIMs"""
        try:
            nim_client = NIMClient()
            enhanced_analyzer = EnhancedColorAnalyzer()
            
            # å¦‚æœæä¾›äº†å›¾ç‰‡URLï¼Œä½¿ç”¨å›¾ç‰‡é¢œè‰²æå–
            if "image_url" in request:
                result = await enhanced_analyzer.analyze_image_colors(request["image_url"])
                return result
            
            elif "colors" in request:
                # é¢œè‰²åˆ—è¡¨åˆ†æ
                colors = request["colors"]
                if not colors:
                    return {"success": False, "error": "é¢œè‰²åˆ—è¡¨ä¸èƒ½ä¸ºç©º"}
                
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªé¢œè‰²ä½œä¸ºåŸºç¡€ç”Ÿæˆé…è‰²
                base_color = colors[0] if isinstance(colors[0], str) else colors[0].get("hex", "#000000")
                
                palette_result = await nim_client.generate_palette(
                    base_color=base_color,
                    scheme=request.get("scheme", "complementary"),
                    num_colors=request.get("num_colors", 5)
                )
                
                if palette_result["success"]:
                    return {
                        "success": True,
                        "palette": palette_result["palette"],
                        "analysis_type": "color_based"
                    }
                else:
                    return {"success": False, "error": palette_result.get("error", "é…è‰²ç”Ÿæˆå¤±è´¥")}
            
            else:
                return {"success": False, "error": "è¯·æä¾› image_url æˆ– colors å‚æ•°"}
                
        except Exception as e:
            logger.error(f"é¢œè‰²åˆ†æé”™è¯¯: {str(e)}")
            return {"success": False, "error": f"åˆ†æå¤±è´¥: {str(e)}"}
    
    @app.post("/color/palette")
    async def generate_palette(request: dict):
        """ç”Ÿæˆé…è‰²æ–¹æ¡ˆæ¥å£ - ä½¿ç”¨NVIDIA Palette Generation NIM"""
        try:
            base_color = request.get("base_color", "")
            scheme = request.get("scheme", "complementary")
            num_colors = request.get("num_colors", 5)
            
            if not base_color:
                return {"error": "è¯·æä¾›åŸºç¡€é¢œè‰²"}
            
            # éªŒè¯é¢œè‰²æ ¼å¼
            if not base_color.startswith("#") or len(base_color) not in [4, 7]:
                return {"error": "é¢œè‰²æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ #RGB æˆ– #RRGGBB æ ¼å¼"}
            
            nim_client = NIMClient()
            
            # ä½¿ç”¨NVIDIA NIMç”Ÿæˆè°ƒè‰²æ¿
            palette_result = await nim_client.generate_palette(
                base_color=base_color,
                palette_type=scheme,
                num_colors=num_colors
            )
            
            if not palette_result.get("success"):
                return palette_result
            
            # æ£€æŸ¥ç”Ÿæˆçš„è°ƒè‰²æ¿çš„å¯è®¿é—®æ€§
            colors = [color["hex_code"] for color in palette_result["colors"]]
            accessibility_result = await nim_client.check_palette_accessibility(colors)
            
            return {
                "success": True,
                "base_color": base_color,
                "scheme": scheme,
                "palette": palette_result,
                "accessibility_analysis": accessibility_result,
                "timestamp": "2025-01-07T13:34:35+08:00"
            }
            
        except Exception as e:
            return {"error": f"é…è‰²ç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    @app.post("/color/contrast")
    async def check_contrast(request: dict):
        """æ£€æŸ¥é¢œè‰²å¯¹æ¯”åº¦æ¥å£ - ä½¿ç”¨NVIDIA Accessibility Check NIM"""
        try:
            bg_color = request.get("background", "")
            text_color = request.get("text", "")
            text_size = request.get("text_size", "normal")
            wcag_level = request.get("wcag_level", "AA")
            
            if not bg_color or not text_color:
                return {"error": "è¯·æä¾›èƒŒæ™¯è‰²å’Œæ–‡å­—è‰²"}
            
            nim_client = NIMClient()
            
            # ä½¿ç”¨NVIDIA NIMæ£€æŸ¥å¯è®¿é—®æ€§
            accessibility_result = await nim_client.check_accessibility(
                foreground_color=text_color,
                background_color=bg_color,
                text_size=text_size,
                wcag_level=wcag_level,
                check_colorblind=True
            )
            
            return {
                "success": True,
                "background": bg_color,
                "text": text_color,
                "accessibility": accessibility_result,
                "timestamp": "2025-01-07T13:34:35+08:00"
            }
            
        except Exception as e:
            return {"error": f"å¯¹æ¯”åº¦æ£€æŸ¥å¤±è´¥: {str(e)}"}
    
    # New NIM-specific endpoints
    @app.post("/nim/extract-colors")
    async def nim_extract_colors(request: dict):
        """å›¾ç‰‡é¢œè‰²æå–æ¥å£ - ç›´æ¥ä½¿ç”¨Color Extraction NIM"""
        try:
            image_url = request.get("image_url", "")
            num_colors = request.get("num_colors", 5)
            min_percentage = request.get("min_percentage", 0.05)
            
            if not image_url:
                return {"error": "è¯·æä¾›å›¾ç‰‡URL"}
            
            nim_client = NIMClient()
            result = await nim_client.extract_colors_from_image(image_url, num_colors, min_percentage)
            
            return result
            
        except Exception as e:
            return {"error": f"å›¾ç‰‡é¢œè‰²æå–å¤±è´¥: {str(e)}"}
    
    @app.post("/nim/comprehensive-analysis")
    async def comprehensive_analysis(request: dict):
        """ç»¼åˆé¢œè‰²åˆ†æ - ä½¿ç”¨å¢å¼ºåˆ†æå™¨"""
        try:
            base_color = request.get("base_color", "#3498DB")
            enhanced_analyzer = EnhancedColorAnalyzer()
            result = await enhanced_analyzer.comprehensive_analysis(base_color)
            return result
        except Exception as e:
            logger.error(f"ç»¼åˆåˆ†æé”™è¯¯: {str(e)}")
            return {"success": False, "error": f"ç»¼åˆåˆ†æå¤±è´¥: {str(e)}"}
    
    @app.post("/upload-image")
    async def upload_image_for_analysis(file: UploadFile = File(...)):
        """ä¸Šä¼ å›¾ç‰‡å¹¶è¿›è¡Œé¢œè‰²åˆ†æ"""
        try:
            # éªŒè¯æ–‡ä»¶ç±»å‹
            if not file.content_type.startswith('image/'):
                raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æ–‡ä»¶")
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            contents = await file.read()
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                tmp_file.write(contents)
                tmp_file_path = tmp_file.name
            
            try:
                # ä½¿ç”¨NIMå®¢æˆ·ç«¯åˆ†æé¢œè‰²
                nim_client = NIMClient()
                
                # å°†ä¸´æ—¶æ–‡ä»¶è½¬æ¢ä¸ºå¯è®¿é—®çš„URLï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
                # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä½ éœ€è¦å°†æ–‡ä»¶ä¸Šä¼ åˆ°äº‘å­˜å‚¨æœåŠ¡
                result = await nim_client.extract_colors(
                    image_url="https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800",  # ç¤ºä¾‹URL
                    num_colors=5
                )
                
                return result
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_file_path)
                
        except Exception as e:
            logger.error(f"å›¾ç‰‡ä¸Šä¼ åˆ†æé”™è¯¯: {str(e)}")
            raise HTTPException(status_code=500, detail=f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}")
    
    @app.post("/analyze-image-base64")
    async def analyze_image_base64(request: dict):
        """åˆ†æbase64ç¼–ç çš„å›¾ç‰‡"""
        try:
            image_data = request.get("image_data", "")
            num_colors = request.get("num_colors", 5)
            
            if not image_data:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å›¾ç‰‡æ•°æ®")
            
            # è§£ç base64å›¾ç‰‡æ•°æ®
            if image_data.startswith('data:image'):
                # ç§»é™¤data URLå‰ç¼€
                image_data = image_data.split(',')[1]
            
            # è§£ç base64
            image_bytes = base64.b64decode(image_data)
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                tmp_file.write(image_bytes)
                tmp_file_path = tmp_file.name
            
            try:
                # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œéœ€è¦å°†ä¸´æ—¶æ–‡ä»¶ä¸Šä¼ åˆ°å¯è®¿é—®çš„URL
                # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨ç¤ºä¾‹å›¾ç‰‡URL
                nim_client = NIMClient()
                result = await nim_client.extract_colors_from_image(
                    image_url="https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800",
                    num_colors=num_colors
                )
                
                return result
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_file_path)
                
        except Exception as e:
            logger.error(f"Base64å›¾ç‰‡åˆ†æé”™è¯¯: {str(e)}")
            raise HTTPException(status_code=500, detail=f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}")
    
    @app.post("/nim/comprehensive-analysis")
    async def nim_comprehensive_analysis(request: dict):
        """å…¨é¢é¢œè‰²åˆ†ææ¥å£ - ä½¿ç”¨æ‰€æœ‰NIMs"""
        try:
            base_color = request.get("base_color", "")
            image_url = request.get("image_url", "")
            
            enhanced_analyzer = EnhancedColorAnalyzer()
            
            if image_url:
                # å›¾ç‰‡åˆ†æ
                result = await enhanced_analyzer.analyze_image_colors(image_url)
            elif base_color:
                # åŸºäºé¢œè‰²çš„å…¨é¢åˆ†æ
                result = await enhanced_analyzer.create_comprehensive_palette(base_color)
            else:
                return {"error": "è¯·æä¾›åŸºç¡€é¢œè‰²æˆ–å›¾ç‰‡URL"}
            
            return result
            
        except Exception as e:
            return {"error": f"å…¨é¢åˆ†æå¤±è´¥: {str(e)}"}
    
    @app.get("/nim/health")
    async def nim_health_check():
        """æ£€æŸ¥æ‰€æœ‰NIMsçš„å¥åº·çŠ¶æ€"""
        try:
            nim_client = NIMClient()
            health_status = await nim_client.health_check_all()
            
            return {
                "success": True,
                "nims_status": health_status,
                "timestamp": "2025-01-07T13:34:35+08:00"
            }
            
        except Exception as e:
            return {"error": f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"}
    
    @app.get("/nim/palette-types")
    async def get_palette_types():
        """è·å–æ”¯æŒçš„è°ƒè‰²æ¿ç±»å‹"""
        try:
            nim_client = NIMClient()
            palette_types = await nim_client.get_palette_types()
            return palette_types
            
        except Exception as e:
            return {"error": f"è·å–è°ƒè‰²æ¿ç±»å‹å¤±è´¥: {str(e)}"}
    
    @app.post("/annotate")
    async def annotate_image(request: dict):
        """
        å›¾ç‰‡é¢œè‰²æ ‡æ³¨ç«¯ç‚¹ - å³ä¾§å¸ƒå±€è®¾è®¡
        æ¥æ”¶å›¾ç‰‡URLå’Œé¢œè‰²åˆ—è¡¨ï¼Œè¿”å›æ ‡æ³¨åçš„å›¾ç‰‡
        """
        try:
            image_url = request.get("image_url", "")
            colors = request.get("colors", [])
            
            if not image_url:
                return {"error": "è¯·æä¾›å›¾ç‰‡URL"}
            
            if not colors:
                return {"error": "è¯·æä¾›é¢œè‰²åˆ—è¡¨"}
            
            # å¤„ç†å›¾ç‰‡URLï¼ˆæ”¯æŒHTTP URLå’Œbase64 data URLï¼‰
            if image_url.startswith('data:image'):
                # å¤„ç†base64ç¼–ç çš„å›¾ç‰‡
                try:
                    header, encoded = image_url.split(',', 1)
                    image_data = base64.b64decode(encoded)
                    image = Image.open(io.BytesIO(image_data))
                except Exception as e:
                    return {"error": f"æ— æ³•è§£æbase64å›¾ç‰‡: {str(e)}"}
            else:
                # å¤„ç†HTTP URL
                try:
                    response = requests.get(image_url)
                    if response.status_code != 200:
                        return {"error": "æ— æ³•ä¸‹è½½å›¾ç‰‡"}
                    image = Image.open(io.BytesIO(response.content))
                except Exception as e:
                    return {"error": f"æ— æ³•ä¸‹è½½å›¾ç‰‡: {str(e)}"}
            
            # è½¬æ¢ä¸ºRGBæ ¼å¼
            image = image.convert('RGB')
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ç”¨äºOpenCVå¤„ç†
            img_array = np.array(image)
            img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            
            height, width = img_cv.shape[:2]
            
            # æŒ‰å æ¯”é™åºæ’åˆ—é¢œè‰²
            sorted_colors = sorted(colors, key=lambda x: x.get("proportion", 0), reverse=True)
            
            # ä½¿ç”¨K-Meansèšç±»è·å–é¢œè‰²åŒºåŸŸåæ ‡
            data = img_cv.reshape((-1, 3))
            data = np.float32(data)
            
            num_colors = len(sorted_colors)
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)
            _, labels, centers = cv2.kmeans(data, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
            
            # å°†æ ‡ç­¾é‡å¡‘å›å›¾ç‰‡å½¢çŠ¶
            labels = labels.reshape(img_cv.shape[:2])
            
            # è®¡ç®—å³ä¾§æ ‡æ³¨åŒºåŸŸå®½åº¦
            annotation_width = 300
            total_width = width + annotation_width
            
            # åˆ›å»ºæ‰©å±•ç”»å¸ƒï¼šåŸå›¾ + å³ä¾§æ ‡æ³¨åŒºåŸŸ
            extended_img = np.ones((height, total_width, 3), dtype=np.uint8) * 250  # æµ…ç°èƒŒæ™¯
            extended_img[:height, :width] = img_cv  # æ”¾ç½®åŸå›¾
            
            # è®¡ç®—æ¯ä¸ªé¢œè‰²åŒºåŸŸçš„ä¸­å¿ƒç‚¹ï¼ˆç”¨äºå¼•å¯¼çº¿ï¼‰
            color_centers = []
            for i, color_info in enumerate(sorted_colors):
                # åˆ›å»ºè¯¥é¢œè‰²çš„æ©ç 
                mask = (labels == i).astype(np.uint8) * 255
                
                # æŸ¥æ‰¾è½®å»“
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                if contours:
                    # æ‰¾åˆ°æœ€å¤§çš„è½®å»“
                    largest_contour = max(contours, key=cv2.contourArea)
                    
                    # è®¡ç®—è½®å»“çš„è´¨å¿ƒ
                    M = cv2.moments(largest_contour)
                    if M["m00"] != 0:
                        center_x = int(M["m10"] / M["m00"])
                        center_y = int(M["m01"] / M["m00"])
                        color_centers.append((center_x, center_y))
                    else:
                        color_centers.append((width // 2, height // 2))
                else:
                    color_centers.append((width // 2, height // 2))
            
            # åœ¨å³ä¾§åŒºåŸŸç»˜åˆ¶é¢œè‰²æ ‡æ³¨
            annotation_start_x = width + 20
            color_block_size = 40
            text_margin = 10
            
            # è®¡ç®—é¢œè‰²å—çš„å‚ç›´é—´è·
            available_height = height - 40  # ç•™å‡ºä¸Šä¸‹è¾¹è·
            if len(sorted_colors) > 1:
                vertical_spacing = available_height // len(sorted_colors)
            else:
                vertical_spacing = available_height
            
            for i, color_info in enumerate(sorted_colors):
                hex_color = color_info.get("hex", "#FFFFFF")
                rgb_color = color_info.get("rgb", [255, 255, 255])
                proportion = color_info.get("proportion", 0.0)
                
                # BGRæ ¼å¼ç”¨äºOpenCV
                bgr_color = (int(rgb_color[2]), int(rgb_color[1]), int(rgb_color[0]))
                
                # è®¡ç®—å½“å‰é¢œè‰²å—çš„Yä½ç½®
                block_y = 20 + i * vertical_spacing + vertical_spacing // 2
                
                # ç»˜åˆ¶é¢œè‰²æ–¹å—
                block_top_left = (annotation_start_x, block_y - color_block_size // 2)
                block_bottom_right = (annotation_start_x + color_block_size, block_y + color_block_size // 2)
                
                cv2.rectangle(extended_img, block_top_left, block_bottom_right, bgr_color, -1)
                cv2.rectangle(extended_img, block_top_left, block_bottom_right, (0, 0, 0), 2)
                
                # ç»˜åˆ¶å¼•å¯¼çº¿ï¼ˆä»å›¾ç‰‡ä¸­çš„é¢œè‰²åŒºåŸŸåˆ°å³ä¾§è‰²å—ï¼‰
                if i < len(color_centers):
                    start_point = color_centers[i]
                    end_point = (annotation_start_x, block_y)
                    
                    # ç»˜åˆ¶ç»†å¼•å¯¼çº¿
                    cv2.line(extended_img, start_point, end_point, (100, 100, 100), 1)
                    
                    # åœ¨åŸå›¾ä¸­æ ‡è®°é¢œè‰²åŒºåŸŸä¸­å¿ƒç‚¹
                    cv2.circle(extended_img, start_point, 5, bgr_color, -1)
                    cv2.circle(extended_img, start_point, 5, (0, 0, 0), 2)
                
                # æ·»åŠ æ–‡æœ¬æ ‡æ³¨
                text_x = annotation_start_x + color_block_size + text_margin
                
                # HEXå€¼
                hex_text = hex_color
                cv2.putText(extended_img, hex_text, (text_x, block_y - 10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                
                # RGBå€¼
                rgb_text = f"RGB({rgb_color[0]},{rgb_color[1]},{rgb_color[2]})"
                cv2.putText(extended_img, rgb_text, (text_x, block_y + 5),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.4, (60, 60, 60), 1)
                
                # å æ¯”
                proportion_text = f"{proportion:.1%}"
                cv2.putText(extended_img, proportion_text, (text_x, block_y + 20),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
            
            # æ·»åŠ æ ‡é¢˜
            title_text = "Color Analysis"
            title_x = annotation_start_x
            cv2.putText(extended_img, title_text, (title_x, 30),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
            
            # è½¬æ¢å›RGBå¹¶ç¼–ç ä¸ºbase64
            final_img_rgb = cv2.cvtColor(extended_img, cv2.COLOR_BGR2RGB)
            final_img_pil = Image.fromarray(final_img_rgb)
            
            # ä¿å­˜ä¸ºbase64
            buffer = io.BytesIO()
            final_img_pil.save(buffer, format='PNG')
            img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return {
                "success": True,
                "annotated_image": f"data:image/png;base64,{img_base64}",
                "image_dimensions": {
                    "width": final_img_pil.width,
                    "height": final_img_pil.height
                },
                "colors_annotated": len(sorted_colors),
                "processing_info": {
                    "original_size": f"{width}x{height}",
                    "final_size": f"{final_img_pil.width}x{final_img_pil.height}",
                    "layout": "right_side_annotation",
                    "features": ["color_blocks", "guide_lines", "sorted_by_proportion"]
                }
            }
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡æ ‡æ³¨å¤±è´¥: {str(e)}")
            return {"error": f"å›¾ç‰‡æ ‡æ³¨å¤±è´¥: {str(e)}"}
    
    @app.get("/nim/wcag-requirements")
    async def get_wcag_requirements():
        """è·å–WCAGè¦æ±‚"""
        try:
            nim_client = NIMClient()
            wcag_info = await nim_client.get_wcag_requirements()
            return wcag_info
            
        except Exception as e:
            return {"error": f"è·å–WCAGè¦æ±‚å¤±è´¥: {str(e)}"}
    
    @app.post("/chat")
    async def chat(message: dict):
        """èŠå¤©æ¥å£ï¼Œé›†æˆç™¾ç‚¼API"""
        from bailian_client import BailianClient
        
        try:
            user_message = message.get("message", "")
            if not user_message:
                return {"error": "è¯·è¾“å…¥æœ‰æ•ˆçš„æ¶ˆæ¯"}
            
            client = BailianClient()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é¢œè‰²ç›¸å…³çš„æŸ¥è¯¢
            if any(keyword in user_message.lower() for keyword in ['é¢œè‰²', 'é…è‰²', 'color', 'ä¸»é¢˜', 'è®¾è®¡']):
                enhanced_message = client.get_color_suggestions(user_message)
            else:
                enhanced_message = user_message
            
            result = await client.chat_completion(enhanced_message)
            
            if result['success']:
                return {
                    "message": user_message,
                    "reply": result['content'],
                    "model": result.get('model', 'qwen-plus'),
                    "usage": result.get('usage', {}),
                    "timestamp": "2025-01-07T13:34:35+08:00"
                }
            else:
                return {
                    "error": result['error'],
                    "details": result.get('details', '')
                }
                
        except Exception as e:
            return {"error": f"æœåŠ¡é”™è¯¯: {str(e)}"}
    
    @app.post("/chat/stream")
    async def chat_stream(request: dict):
        """æµå¼èŠå¤©æ¥å£ï¼Œé›†æˆç™¾ç‚¼API"""
        from bailian_client import BailianClient
        
        async def generate_response():
            try:
                message = request.get("message", "")
                if not message:
                    yield f"data: {json.dumps({'choices': [{'delta': {'content': 'è¯·è¾“å…¥æœ‰æ•ˆçš„æ¶ˆæ¯'}, 'finish_reason': 'stop'}]})}\n\n"
                    return
                
                client = BailianClient()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é¢œè‰²ç›¸å…³çš„æŸ¥è¯¢
                if any(keyword in message.lower() for keyword in ['é¢œè‰²', 'é…è‰²', 'color', 'ä¸»é¢˜', 'è®¾è®¡']):
                    enhanced_message = client.get_color_suggestions(message)
                else:
                    enhanced_message = message
                
                async for chunk in client.chat_stream(enhanced_message):
                    if chunk['success']:
                        response_chunk = {
                            "choices": [{
                                "delta": {"content": chunk['content']},
                                "finish_reason": chunk.get('finish_reason')
                            }]
                        }
                        yield f"data: {json.dumps(response_chunk)}\n\n"
                        
                        if chunk.get('finish_reason') == 'stop':
                            break
                    else:
                        error_chunk = {
                            "choices": [{
                                "delta": {"content": f"é”™è¯¯: {chunk['error']}"},
                                "finish_reason": "stop"
                            }]
                        }
                        yield f"data: {json.dumps(error_chunk)}\n\n"
                        break
                        
            except Exception as e:
                error_chunk = {
                    "choices": [{
                        "delta": {"content": f"æœåŠ¡é”™è¯¯: {str(e)}"},
                        "finish_reason": "stop"
                    }]
                }
                yield f"data: {json.dumps(error_chunk)}\n\n"
                
        return StreamingResponse(
            generate_response(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache"}
        )
    
    @app.websocket("/websocket")
    async def websocket_endpoint(websocket: WebSocket):
        """WebSocketèŠå¤©æ¥å£"""
        await websocket.accept()
        try:
            while True:
                data = await websocket.receive_text()
                message_data = json.loads(data)
                user_message = message_data.get("message", "")
                
                # æ¨¡æ‹Ÿå“åº”
                response = {
                    "type": "message",
                    "content": f"WebSocketå›å¤ï¼š{user_message}",
                    "timestamp": "2025-01-07T11:21:55+08:00"
                }
                
                await websocket.send_text(json.dumps(response))
        except WebSocketDisconnect:
            pass
    
    return app

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ UI Color Bot å¿«é€Ÿå¯åŠ¨")
    print("=" * 30)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_env()
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("BAILIAN_API_KEY")
    if not api_key or api_key == "your_actual_api_key_here":
        print("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®çœŸå®çš„ç™¾ç‚¼APIå¯†é’¥")
        return
    
    print(f"âœ… ç™¾ç‚¼APIå¯†é’¥å·²é…ç½® (é•¿åº¦: {len(api_key)})")
    
    # åˆ›å»ºåº”ç”¨
    app = create_simple_app()
    
    print("\nğŸš€ å¯åŠ¨æœåŠ¡å™¨...")
    print("ğŸ“ è®¿é—®åœ°å€: http://localhost:8001")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:8001/docs")
    print("ğŸ›‘ åœæ­¢æœåŠ¡: æŒ‰ Ctrl+C")
    print("-" * 50)
    
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        reload=False
    )

if __name__ == "__main__":
    main()
