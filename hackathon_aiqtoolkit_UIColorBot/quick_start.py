#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬ - ç›´æ¥ä½¿ç”¨FastAPIå¯åŠ¨æœåŠ¡
"""

import asyncio
import json
import logging
import os
import tempfile
import uuid
from pathlib import Path
from typing import Dict, Any, List, Optional
import base64
import io

import httpx
import uvicorn
import yaml
import requests
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from sklearn.cluster import KMeans
from dotenv import load_dotenv
from fastapi import FastAPI, Request, HTTPException, File, UploadFile, WebSocket
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import uvicorn
from pathlib import Path
from config_loader import load_config_with_env
from bailian_client import BailianClient
from color_utils import ColorUtils
from nim_client import NIMClient, EnhancedColorAnalyzer

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_env():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    from dotenv import load_dotenv
    env_path = Path(__file__).parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        # æ‰“å°åŠ è½½çš„ç¯å¢ƒå˜é‡ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
        for key in ['BAILIAN_API_KEY', 'DASHSCOPE_API_KEY', 'TAVILY_API_KEY']:
            value = os.getenv(key)
            if value:
                print(f"âœ… åŠ è½½ç¯å¢ƒå˜é‡: {key} = {value[:10]}...")
        print("âœ… ç¯å¢ƒå˜é‡åŠ è½½å®Œæˆ")
    else:
        print("âŒ æœªæ‰¾åˆ° .env æ–‡ä»¶")

def create_simple_app():
    """åˆ›å»ºç®€å•çš„FastAPIåº”ç”¨"""
    app = FastAPI(
        title="UI Color Bot API",
        description="åŸºäºç™¾ç‚¼APIçš„UIé¢œè‰²åŠ©æ‰‹",
        version="1.0.0"
    )
    
    # æ·»åŠ CORSä¸­é—´ä»¶æ”¯æŒå‰ç«¯è®¿é—®
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    @app.get("/")
    async def root():
        return {"message": "UI Color Bot API è¿è¡Œä¸­", "status": "ok"}
    
    @app.get("/health")
    async def health():
        return {"status": "healthy", "api_configured": bool(os.getenv("BAILIAN_API_KEY"))}
    
    @app.post("/color/analyze")
    async def analyze_colors(request: dict):
        """é¢œè‰²åˆ†ææ¥å£ - é›†æˆNVIDIA NIMs"""
        try:
            nim_client = NIMClient()
            enhanced_analyzer = EnhancedColorAnalyzer()
            
            # å¦‚æœæä¾›äº†å›¾ç‰‡URLï¼Œä½¿ç”¨å›¾ç‰‡é¢œè‰²æå–
            if "image_url" in request:
                result = await enhanced_analyzer.analyze_image_colors(request["image_url"])
                return result
            
            elif "colors" in request:
                # é¢œè‰²åˆ—è¡¨åˆ†æ
                colors = request["colors"]
                if not colors:
                    return {"success": False, "error": "é¢œè‰²åˆ—è¡¨ä¸èƒ½ä¸ºç©º"}
                
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªé¢œè‰²ä½œä¸ºåŸºç¡€ç”Ÿæˆé…è‰²
                base_color = colors[0] if isinstance(colors[0], str) else colors[0].get("hex", "#000000")
                
                palette_result = await nim_client.generate_palette(
                    base_color=base_color,
                    scheme=request.get("scheme", "complementary"),
                    num_colors=request.get("num_colors", 5)
                )
                
                if palette_result["success"]:
                    return {
                        "success": True,
                        "palette": palette_result["palette"],
                        "analysis_type": "color_based"
                    }
                else:
                    return {"success": False, "error": palette_result.get("error", "é…è‰²ç”Ÿæˆå¤±è´¥")}
            
            else:
                return {"success": False, "error": "è¯·æä¾› image_url æˆ– colors å‚æ•°"}
                
        except Exception as e:
            logger.error(f"é¢œè‰²åˆ†æé”™è¯¯: {str(e)}")
            return {"success": False, "error": f"åˆ†æå¤±è´¥: {str(e)}"}
    
    @app.post("/color/palette")
    async def generate_palette(request: dict):
        """ç”Ÿæˆé…è‰²æ–¹æ¡ˆæ¥å£ - ä½¿ç”¨NVIDIA Palette Generation NIM"""
        try:
            base_color = request.get("base_color", "")
            scheme = request.get("scheme", "complementary")
            num_colors = request.get("num_colors", 5)
            
            if not base_color:
                return {"error": "è¯·æä¾›åŸºç¡€é¢œè‰²"}
            
            # éªŒè¯é¢œè‰²æ ¼å¼
            if not base_color.startswith("#") or len(base_color) not in [4, 7]:
                return {"error": "é¢œè‰²æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ #RGB æˆ– #RRGGBB æ ¼å¼"}
            
            nim_client = NIMClient()
            
            # ä½¿ç”¨NVIDIA NIMç”Ÿæˆè°ƒè‰²æ¿
            palette_result = await nim_client.generate_palette(
                base_color=base_color,
                palette_type=scheme,
                num_colors=num_colors
            )
            
            if not palette_result.get("success"):
                return palette_result
            
            # æ£€æŸ¥ç”Ÿæˆçš„è°ƒè‰²æ¿çš„å¯è®¿é—®æ€§
            colors = [color["hex_code"] for color in palette_result["colors"]]
            accessibility_result = await nim_client.check_palette_accessibility(colors)
            
            return {
                "success": True,
                "base_color": base_color,
                "scheme": scheme,
                "palette": palette_result,
                "accessibility_analysis": accessibility_result,
                "timestamp": "2025-01-07T13:34:35+08:00"
            }
            
        except Exception as e:
            return {"error": f"é…è‰²ç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    @app.post("/color/contrast")
    async def check_contrast(request: dict):
        """æ£€æŸ¥é¢œè‰²å¯¹æ¯”åº¦æ¥å£ - ä½¿ç”¨NVIDIA Accessibility Check NIM"""
        try:
            bg_color = request.get("background", "")
            text_color = request.get("text", "")
            text_size = request.get("text_size", "normal")
            wcag_level = request.get("wcag_level", "AA")
            
            if not bg_color or not text_color:
                return {"error": "è¯·æä¾›èƒŒæ™¯è‰²å’Œæ–‡å­—è‰²"}
            
            nim_client = NIMClient()
            
            # ä½¿ç”¨NVIDIA NIMæ£€æŸ¥å¯è®¿é—®æ€§
            accessibility_result = await nim_client.check_accessibility(
                foreground_color=text_color,
                background_color=bg_color,
                text_size=text_size,
                wcag_level=wcag_level,
                check_colorblind=True
            )
            
            return {
                "success": True,
                "background": bg_color,
                "text": text_color,
                "accessibility": accessibility_result,
                "timestamp": "2025-01-07T13:34:35+08:00"
            }
            
        except Exception as e:
            return {"error": f"å¯¹æ¯”åº¦æ£€æŸ¥å¤±è´¥: {str(e)}"}
    
    # New NIM-specific endpoints
    @app.post("/nim/extract-colors")
    async def nim_extract_colors(request: dict):
        """å›¾ç‰‡é¢œè‰²æå–æ¥å£ - ç›´æ¥ä½¿ç”¨Color Extraction NIM"""
        try:
            image_url = request.get("image_url", "")
            num_colors = request.get("num_colors", 5)
            min_percentage = request.get("min_percentage", 0.05)
            
            if not image_url:
                return {"error": "è¯·æä¾›å›¾ç‰‡URL"}
            
            nim_client = NIMClient()
            result = await nim_client.extract_colors_from_image(image_url, num_colors, min_percentage)
            
            return result
            
        except Exception as e:
            return {"error": f"å›¾ç‰‡é¢œè‰²æå–å¤±è´¥: {str(e)}"}
    
    @app.post("/nim/comprehensive-analysis")
    async def comprehensive_analysis(request: dict):
        """ç»¼åˆé¢œè‰²åˆ†æ - ä½¿ç”¨å¢å¼ºåˆ†æå™¨"""
        try:
            base_color = request.get("base_color", "#3498DB")
            enhanced_analyzer = EnhancedColorAnalyzer()
            result = await enhanced_analyzer.comprehensive_analysis(base_color)
            return result
        except Exception as e:
            logger.error(f"ç»¼åˆåˆ†æé”™è¯¯: {str(e)}")
            return {"success": False, "error": f"ç»¼åˆåˆ†æå¤±è´¥: {str(e)}"}
    
    @app.post("/upload-image")
    async def upload_image_for_analysis(file: UploadFile = File(...)):
        """ä¸Šä¼ å›¾ç‰‡å¹¶è¿›è¡Œé¢œè‰²åˆ†æ"""
        try:
            # éªŒè¯æ–‡ä»¶ç±»å‹
            if not file.content_type.startswith('image/'):
                raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æ–‡ä»¶")
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            contents = await file.read()
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                tmp_file.write(contents)
                tmp_file_path = tmp_file.name
            
            try:
                # ä½¿ç”¨NIMå®¢æˆ·ç«¯åˆ†æé¢œè‰²
                nim_client = NIMClient()
                
                # å°†ä¸´æ—¶æ–‡ä»¶è½¬æ¢ä¸ºå¯è®¿é—®çš„URLï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
                # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä½ éœ€è¦å°†æ–‡ä»¶ä¸Šä¼ åˆ°äº‘å­˜å‚¨æœåŠ¡
                result = await nim_client.extract_colors(
                    image_url="https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800",  # ç¤ºä¾‹URL
                    num_colors=5
                )
                
                return result
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_file_path)
                
        except Exception as e:
            logger.error(f"å›¾ç‰‡ä¸Šä¼ åˆ†æé”™è¯¯: {str(e)}")
            raise HTTPException(status_code=500, detail=f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}")
    
    @app.post("/analyze-image-base64")
    async def analyze_image_base64(request: dict):
        """åˆ†æbase64ç¼–ç çš„å›¾ç‰‡ï¼Œä½¿ç”¨HSVè‰²å½©ç©ºé—´ä¼˜åŒ–"""
        try:
            image_data = request.get("image_data", "")
            num_colors = request.get("num_colors", 5)
            
            if not image_data:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å›¾ç‰‡æ•°æ®")
            
            # è§£ç base64å›¾ç‰‡æ•°æ®
            if image_data.startswith('data:image'):
                # ç§»é™¤data URLå‰ç¼€
                image_data = image_data.split(',')[1]
            
            # è§£ç base64å¹¶ç›´æ¥å¤„ç†å›¾ç‰‡
            image_bytes = base64.b64decode(image_data)
            
            # ä½¿ç”¨PILå’ŒOpenCVç›´æ¥å¤„ç†å›¾ç‰‡ï¼Œç¡®ä¿æ­£ç¡®çš„è‰²å½©ç©ºé—´è½¬æ¢
            import io
            from PIL import Image
            import cv2
            import numpy as np
            from sklearn.cluster import KMeans
            import time
            
            start_time = time.time()
            
            # ä»å­—èŠ‚æ•°æ®åˆ›å»ºPILå›¾åƒ
            pil_image = Image.open(io.BytesIO(image_bytes))
            
            # è½¬æ¢ä¸ºRGBæ ¼å¼
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            image_array = np.array(pil_image)
            
            # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥æé«˜æ€§èƒ½
            height, width = image_array.shape[:2]
            if width > 800 or height > 800:
                scale = min(800/width, 800/height)
                new_width = int(width * scale)
                new_height = int(height * scale)
                image_array = cv2.resize(image_array, (new_width, new_height))
            
            # å…³é”®ï¼šç¡®ä¿æ­£ç¡®çš„è‰²å½©ç©ºé—´è½¬æ¢
            # PILä½¿ç”¨RGBæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºBGRä¾›OpenCVå¤„ç†
            image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
            
            # è½¬æ¢BGRåˆ°HSVè‰²å½©ç©ºé—´è¿›è¡Œæ›´å‡†ç¡®çš„é¢œè‰²åˆ†æ
            image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)
            
            # åœ¨HSVç©ºé—´è¿›è¡ŒK-Meansèšç±»
            pixels_hsv = image_hsv.reshape(-1, 3)
            
            # åº”ç”¨K-Meansèšç±»
            kmeans = KMeans(n_clusters=num_colors, random_state=42, n_init=10)
            labels = kmeans.fit_predict(pixels_hsv)
            
            # è·å–HSVç©ºé—´çš„èšç±»ä¸­å¿ƒ
            colors_hsv = kmeans.cluster_centers_
            
            # å°†HSVèšç±»ä¸­å¿ƒè½¬æ¢å›RGBç”¨äºæ˜¾ç¤º
            colors_rgb = []
            percentages = []
            
            unique_labels, counts = np.unique(labels, return_counts=True)
            total_pixels = len(pixels_hsv)
            
            for i, (hsv_color, count) in enumerate(zip(colors_hsv, counts)):
                # è½¬æ¢HSVåˆ°BGRå†åˆ°RGB
                hsv_pixel = np.uint8([[hsv_color]])
                bgr_pixel = cv2.cvtColor(hsv_pixel, cv2.COLOR_HSV2BGR)
                rgb_pixel = cv2.cvtColor(bgr_pixel, cv2.COLOR_BGR2RGB)[0][0]
                
                colors_rgb.append(rgb_pixel.tolist())
                percentages.append(count / total_pixels)
            
            # æŒ‰å æ¯”æ’åº
            sorted_indices = np.argsort(percentages)[::-1]
            colors_rgb = [colors_rgb[i] for i in sorted_indices]
            percentages = [percentages[i] for i in sorted_indices]
            
            # æ„å»ºå“åº”
            colors_info = []
            for rgb, percentage in zip(colors_rgb, percentages):
                if percentage >= 0.05:  # æœ€å°å æ¯”é˜ˆå€¼
                    hex_code = "#{:02x}{:02x}{:02x}".format(int(rgb[0]), int(rgb[1]), int(rgb[2]))
                    
                    # ç®€å•çš„é¢œè‰²å‘½å
                    r, g, b = rgb
                    if r > 200 and g > 200 and b > 200:
                        color_name = "æµ…è‰²"
                    elif r < 50 and g < 50 and b < 50:
                        color_name = "æ·±è‰²"
                    elif r > g and r > b:
                        color_name = "çº¢è‰²ç³»"
                    elif g > r and g > b:
                        color_name = "ç»¿è‰²ç³»"
                    elif b > r and b > g:
                        color_name = "è“è‰²ç³»"
                    elif r > 150 and g > 150 and b < 100:
                        color_name = "é»„è‰²ç³»"
                    elif r > 150 and g < 100 and b > 150:
                        color_name = "ç´«è‰²ç³»"
                    elif r < 100 and g > 150 and b > 150:
                        color_name = "é’è‰²ç³»"
                    else:
                        color_name = "æ··åˆè‰²"
                    
                    colors_info.append({
                        "hex_code": hex_code,
                        "rgb": [int(c) for c in rgb],
                        "percentage": percentage,
                        "color_name": color_name
                    })
            
            processing_time = (time.time() - start_time) * 1000
            
            return {
                "success": True,
                "colors": colors_info,
                "total_colors_found": len(colors_info),
                "processing_time_ms": processing_time,
                "algorithm_used": "K-Means with HSV color space",
                "image_dimensions": {"width": width, "height": height}
            }
                
        except Exception as e:
            logger.error(f"Base64å›¾ç‰‡åˆ†æé”™è¯¯: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Base64å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}")
    
    @app.post("/nim/comprehensive-analysis")
    async def nim_comprehensive_analysis(request: dict):
        """å…¨é¢é¢œè‰²åˆ†ææ¥å£ - ä½¿ç”¨æ‰€æœ‰NIMs"""
        try:
            base_color = request.get("base_color", "")
            image_url = request.get("image_url", "")
            
            enhanced_analyzer = EnhancedColorAnalyzer()
            
            if image_url:
                # å›¾ç‰‡åˆ†æ
                result = await enhanced_analyzer.analyze_image_colors(image_url)
            elif base_color:
                # åŸºäºé¢œè‰²çš„å…¨é¢åˆ†æ
                result = await enhanced_analyzer.create_comprehensive_palette(base_color)
            else:
                return {"error": "è¯·æä¾›åŸºç¡€é¢œè‰²æˆ–å›¾ç‰‡URL"}
            
            return result
            
        except Exception as e:
            return {"error": f"å…¨é¢åˆ†æå¤±è´¥: {str(e)}"}
    
    @app.get("/nim/health")
    async def nim_health_check():
        """æ£€æŸ¥æ‰€æœ‰NIMsçš„å¥åº·çŠ¶æ€"""
        try:
            nim_client = NIMClient()
            health_status = await nim_client.health_check_all()
            
            return {
                "success": True,
                "nims_status": health_status,
                "timestamp": "2025-01-07T13:34:35+08:00"
            }
            
        except Exception as e:
            return {"error": f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"}
    
    @app.get("/nim/palette-types")
    async def get_palette_types():
        """è·å–æ”¯æŒçš„è°ƒè‰²æ¿ç±»å‹"""
        try:
            nim_client = NIMClient()
            palette_types = await nim_client.get_palette_types()
            return palette_types
            
        except Exception as e:
            return {"error": f"è·å–è°ƒè‰²æ¿ç±»å‹å¤±è´¥: {str(e)}"}
    
    @app.post("/pick-color")
    async def pick_color_at_position(request: dict):
        """
        ç‚¹å‡»å–è‰²ç«¯ç‚¹ - è·å–å›¾ç‰‡æŒ‡å®šä½ç½®çš„é¢œè‰²
        æ¥æ”¶å›¾ç‰‡URLå’Œç‚¹å‡»åæ ‡ï¼Œè¿”å›è¯¥ä½ç½®çš„é¢œè‰²ä¿¡æ¯
        """
        try:
            image_url = request.get("image_url", "")
            x = request.get("x", 0)
            y = request.get("y", 0)
            
            if not image_url:
                return {"error": "è¯·æä¾›å›¾ç‰‡URL"}
            
            # å¤„ç†å›¾ç‰‡URLï¼ˆæ”¯æŒHTTP URLå’Œbase64 data URLï¼‰
            if image_url.startswith('data:image'):
                # å¤„ç†base64ç¼–ç çš„å›¾ç‰‡
                try:
                    header, encoded = image_url.split(',', 1)
                    image_data = base64.b64decode(encoded)
                    image = Image.open(io.BytesIO(image_data))
                except Exception as e:
                    return {"error": f"æ— æ³•è§£æbase64å›¾ç‰‡: {str(e)}"}
            else:
                # å¤„ç†HTTP URL
                try:
                    response = requests.get(image_url)
                    if response.status_code != 200:
                        return {"error": "æ— æ³•ä¸‹è½½å›¾ç‰‡"}
                    image = Image.open(io.BytesIO(response.content))
                except Exception as e:
                    return {"error": f"æ— æ³•ä¸‹è½½å›¾ç‰‡: {str(e)}"}
            
            # è½¬æ¢ä¸ºRGBæ ¼å¼
            image = image.convert('RGB')
            width, height = image.size
            
            # éªŒè¯åæ ‡èŒƒå›´
            if x < 0 or x >= width or y < 0 or y >= height:
                return {"error": f"åæ ‡è¶…å‡ºå›¾ç‰‡èŒƒå›´: ({x}, {y}), å›¾ç‰‡å°ºå¯¸: {width}x{height}"}
            
            # è·å–æŒ‡å®šä½ç½®çš„åƒç´ é¢œè‰²
            pixel_color = image.getpixel((x, y))
            rgb_color = list(pixel_color[:3])  # ç¡®ä¿åªå–RGBä¸‰ä¸ªé€šé“
            
            # è½¬æ¢ä¸ºåå…­è¿›åˆ¶
            hex_color = "#{:02x}{:02x}{:02x}".format(rgb_color[0], rgb_color[1], rgb_color[2])
            
            # è·å–é¢œè‰²åç§°ï¼ˆç®€å•åˆ†ç±»ï¼‰
            def get_color_name(rgb):
                r, g, b = rgb
                # è½¬æ¢ä¸ºHSVè¿›è¡Œé¢œè‰²åˆ†ç±»
                max_val = max(r, g, b)
                min_val = min(r, g, b)
                diff = max_val - min_val
                
                if diff < 30:  # ç°åº¦é¢œè‰²
                    if max_val > 200:
                        return "ç™½è‰²"
                    elif max_val < 50:
                        return "é»‘è‰²"
                    else:
                        return "ç°è‰²"
                
                # è®¡ç®—ä¸»è¦é¢œè‰²
                if r > g and r > b:
                    if g > b:
                        return "æ©™è‰²" if r - g < 50 else "çº¢è‰²"
                    else:
                        return "ç²‰è‰²" if b > 100 else "çº¢è‰²"
                elif g > r and g > b:
                    if r > b:
                        return "é»„ç»¿è‰²" if g - r < 50 else "ç»¿è‰²"
                    else:
                        return "é’è‰²" if b > 100 else "ç»¿è‰²"
                elif b > r and b > g:
                    if r > g:
                        return "ç´«è‰²"
                    else:
                        return "è“è‰²"
                else:
                    return "æ··åˆè‰²"
            
            color_name = get_color_name(rgb_color)
            
            return {
                "success": True,
                "color": {
                    "hex": hex_color,
                    "rgb": rgb_color,
                    "color_name": color_name,
                    "position": {"x": x, "y": y}
                },
                "image_dimensions": {"width": width, "height": height}
            }
            
        except Exception as e:
            return {"error": f"å–è‰²å¤±è´¥: {str(e)}"}
    
    @app.post("/annotate")
    async def annotate_image(request: dict):
        """
        å›¾ç‰‡é¢œè‰²æ ‡æ³¨ç«¯ç‚¹ - å³ä¾§å¸ƒå±€è®¾è®¡
        æ¥æ”¶å›¾ç‰‡URLå’Œé¢œè‰²åˆ—è¡¨ï¼Œè¿”å›æ ‡æ³¨åçš„å›¾ç‰‡
        """
        try:
            image_url = request.get("image_url", "")
            colors = request.get("colors", [])
            
            if not image_url:
                return {"error": "è¯·æä¾›å›¾ç‰‡URL"}
            
            if not colors:
                return {"error": "è¯·æä¾›é¢œè‰²åˆ—è¡¨"}
            
            # å¤„ç†å›¾ç‰‡URLï¼ˆæ”¯æŒHTTP URLå’Œbase64 data URLï¼‰
            if image_url.startswith('data:image'):
                # å¤„ç†base64ç¼–ç çš„å›¾ç‰‡
                try:
                    header, encoded = image_url.split(',', 1)
                    image_data = base64.b64decode(encoded)
                    image = Image.open(io.BytesIO(image_data))
                except Exception as e:
                    return {"error": f"æ— æ³•è§£æbase64å›¾ç‰‡: {str(e)}"}
            else:
                # å¤„ç†HTTP URL
                try:
                    response = requests.get(image_url)
                    if response.status_code != 200:
                        return {"error": "æ— æ³•ä¸‹è½½å›¾ç‰‡"}
                    image = Image.open(io.BytesIO(response.content))
                except Exception as e:
                    return {"error": f"æ— æ³•ä¸‹è½½å›¾ç‰‡: {str(e)}"}
            
            # è½¬æ¢ä¸ºRGBæ ¼å¼
            image = image.convert('RGB')
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ç”¨äºOpenCVå¤„ç†
            img_array = np.array(image)
            img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            
            height, width = img_cv.shape[:2]
            
            # æŒ‰å æ¯”é™åºæ’åˆ—é¢œè‰²
            sorted_colors = sorted(colors, key=lambda x: x.get("proportion", 0), reverse=True)
            
            # è®¡ç®—å³ä¾§æ ‡æ³¨åŒºåŸŸå®½åº¦
            annotation_width = 300
            total_width = width + annotation_width
            
            # åˆ›å»ºæ‰©å±•ç”»å¸ƒï¼šåŸå›¾ + å³ä¾§æ ‡æ³¨åŒºåŸŸ
            extended_img = np.ones((height, total_width, 3), dtype=np.uint8) * 250  # æµ…ç°èƒŒæ™¯
            extended_img[:height, :width] = img_cv  # æ”¾ç½®åŸå›¾
            
            # è®¡ç®—æ¯ä¸ªé¢œè‰²åŒºåŸŸçš„ä¸­å¿ƒç‚¹ï¼ˆç”¨äºå¼•å¯¼çº¿ï¼‰
            color_centers = []
            for color_info in sorted_colors:
                rgb_color = color_info.get("rgb", [255, 255, 255])
                target_bgr = np.array([rgb_color[2], rgb_color[1], rgb_color[0]], dtype=np.float32)
                
                # è½¬æ¢åˆ°HSVè‰²å½©ç©ºé—´è¿›è¡Œæ›´å‡†ç¡®çš„é¢œè‰²åŒ¹é…
                target_hsv = cv2.cvtColor(np.uint8([[target_bgr]]), cv2.COLOR_BGR2HSV)[0][0].astype(np.float32)
                img_hsv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV).astype(np.float32)
                
                # è®¡ç®—HSVè‰²å½©ç©ºé—´ä¸­çš„è·ç¦»ï¼ˆè€ƒè™‘è‰²ç›¸çš„å‘¨æœŸæ€§ï¼‰
                h_diff = np.abs(img_hsv[:,:,0] - target_hsv[0])
                h_diff = np.minimum(h_diff, 180 - h_diff)  # å¤„ç†è‰²ç›¸çš„å‘¨æœŸæ€§
                s_diff = np.abs(img_hsv[:,:,1] - target_hsv[1])
                v_diff = np.abs(img_hsv[:,:,2] - target_hsv[2])
                
                # åŠ æƒHSVè·ç¦»è®¡ç®—ï¼ˆè‰²ç›¸æƒé‡æ›´é«˜ï¼‰
                hsv_distance = np.sqrt(
                    (h_diff * 2.0) ** 2 +  # è‰²ç›¸æƒé‡åŠ å€
                    (s_diff * 1.0) ** 2 +  # é¥±å’Œåº¦æ ‡å‡†æƒé‡
                    (v_diff * 0.5) ** 2    # æ˜åº¦æƒé‡å‡åŠ
                )
                
                # è‡ªé€‚åº”é˜ˆå€¼ï¼šåŸºäºç›®æ ‡é¢œè‰²çš„é¥±å’Œåº¦å’Œæ˜åº¦è°ƒæ•´
                base_threshold = 40
                if target_hsv[1] < 50:  # ä½é¥±å’Œåº¦é¢œè‰²ï¼ˆç°è‰²ç³»ï¼‰
                    threshold = base_threshold * 1.5
                elif target_hsv[2] < 50:  # ä½æ˜åº¦é¢œè‰²ï¼ˆæš—è‰²ç³»ï¼‰
                    threshold = base_threshold * 1.2
                else:
                    threshold = base_threshold
                
                # åˆ›å»ºé¢œè‰²æ©ç 
                mask = (hsv_distance < threshold).astype(np.uint8) * 255
                
                # å½¢æ€å­¦æ“ä½œä¼˜åŒ–
                kernel_small = np.ones((3,3), np.uint8)
                kernel_large = np.ones((7,7), np.uint8)
                
                # å…ˆé—­è¿ç®—è¿æ¥ç›¸è¿‘åŒºåŸŸï¼Œå†å¼€è¿ç®—å»é™¤å™ªå£°
                mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_large)
                mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_small)
                
                # æŸ¥æ‰¾è½®å»“
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                if contours:
                    # è¿‡æ»¤æ‰å¤ªå°çš„è½®å»“
                    min_area = (width * height) * 0.001  # è‡³å°‘å å›¾åƒé¢ç§¯çš„0.1%
                    valid_contours = [c for c in contours if cv2.contourArea(c) > min_area]
                    
                    if valid_contours:
                        # æ‰¾åˆ°æœ€å¤§çš„æœ‰æ•ˆè½®å»“
                        largest_contour = max(valid_contours, key=cv2.contourArea)
                        
                        # è®¡ç®—è½®å»“çš„è´¨å¿ƒ
                        M = cv2.moments(largest_contour)
                        if M["m00"] != 0:
                            center_x = int(M["m10"] / M["m00"])
                            center_y = int(M["m01"] / M["m00"])
                            color_centers.append((center_x, center_y))
                        else:
                            # ä½¿ç”¨è½®å»“è¾¹ç•Œæ¡†ä¸­å¿ƒ
                            x, y, w, h = cv2.boundingRect(largest_contour)
                            color_centers.append((x + w//2, y + h//2))
                    else:
                        # ä½¿ç”¨æ©ç çš„åŠ æƒä¸­å¿ƒ
                        y_coords, x_coords = np.where(mask > 0)
                        if len(x_coords) > 0:
                            center_x = int(np.mean(x_coords))
                            center_y = int(np.mean(y_coords))
                            color_centers.append((center_x, center_y))
                        else:
                            color_centers.append((width // 2, height // 2))
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è½®å»“ï¼Œä½¿ç”¨æœ€ç›¸ä¼¼åƒç´ çš„ä½ç½®
                    min_distance_idx = np.unravel_index(np.argmin(hsv_distance), hsv_distance.shape)
                    color_centers.append((min_distance_idx[1], min_distance_idx[0]))
            
            # åœ¨å³ä¾§åŒºåŸŸç»˜åˆ¶é¢œè‰²æ ‡æ³¨
            annotation_start_x = width + 20
            color_block_size = 40
            text_margin = 10
            
            # è®¡ç®—é¢œè‰²å—çš„å‚ç›´é—´è·
            available_height = height - 40  # ç•™å‡ºä¸Šä¸‹è¾¹è·
            if len(sorted_colors) > 1:
                vertical_spacing = available_height // len(sorted_colors)
            else:
                vertical_spacing = available_height
            
            for i, color_info in enumerate(sorted_colors):
                hex_color = color_info.get("hex", "#FFFFFF")
                rgb_color = color_info.get("rgb", [255, 255, 255])
                proportion = color_info.get("proportion", 0.0)
                
                # BGRæ ¼å¼ç”¨äºOpenCV
                bgr_color = (int(rgb_color[2]), int(rgb_color[1]), int(rgb_color[0]))
                
                # è®¡ç®—å½“å‰é¢œè‰²å—çš„Yä½ç½®
                block_y = 20 + i * vertical_spacing + vertical_spacing // 2
                
                # ç»˜åˆ¶é¢œè‰²æ–¹å—
                block_top_left = (annotation_start_x, block_y - color_block_size // 2)
                block_bottom_right = (annotation_start_x + color_block_size, block_y + color_block_size // 2)
                
                cv2.rectangle(extended_img, block_top_left, block_bottom_right, bgr_color, -1)
                cv2.rectangle(extended_img, block_top_left, block_bottom_right, (0, 0, 0), 2)
                
                # ç»˜åˆ¶å¼•å¯¼çº¿ï¼ˆä»å›¾ç‰‡ä¸­çš„é¢œè‰²åŒºåŸŸåˆ°å³ä¾§è‰²å—ï¼‰
                if i < len(color_centers):
                    start_point = color_centers[i]
                    end_point = (annotation_start_x, block_y)
                    
                    # ç»˜åˆ¶ç»†å¼•å¯¼çº¿
                    cv2.line(extended_img, start_point, end_point, (100, 100, 100), 1)
                    
                    # åœ¨åŸå›¾ä¸­æ ‡è®°é¢œè‰²åŒºåŸŸä¸­å¿ƒç‚¹
                    cv2.circle(extended_img, start_point, 5, bgr_color, -1)
                    cv2.circle(extended_img, start_point, 5, (0, 0, 0), 2)
                
                # æ·»åŠ æ–‡æœ¬æ ‡æ³¨
                text_x = annotation_start_x + color_block_size + text_margin
                
                # HEXå€¼
                hex_text = hex_color
                cv2.putText(extended_img, hex_text, (text_x, block_y - 10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                
                # RGBå€¼
                rgb_text = f"RGB({rgb_color[0]},{rgb_color[1]},{rgb_color[2]})"
                cv2.putText(extended_img, rgb_text, (text_x, block_y + 5),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.4, (60, 60, 60), 1)
                
                # å æ¯”
                proportion_text = f"{proportion:.1%}"
                cv2.putText(extended_img, proportion_text, (text_x, block_y + 20),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
            
            # æ·»åŠ æ ‡é¢˜
            title_text = "Color Analysis"
            title_x = annotation_start_x
            cv2.putText(extended_img, title_text, (title_x, 30),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
            
            # è½¬æ¢å›RGBå¹¶ç¼–ç ä¸ºbase64
            final_img_rgb = cv2.cvtColor(extended_img, cv2.COLOR_BGR2RGB)
            final_img_pil = Image.fromarray(final_img_rgb)
            
            # ä¿å­˜ä¸ºbase64
            buffer = io.BytesIO()
            final_img_pil.save(buffer, format='PNG')
            img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return {
                "success": True,
                "annotated_image": f"data:image/png;base64,{img_base64}",
                "image_dimensions": {
                    "width": final_img_pil.width,
                    "height": final_img_pil.height
                },
                "colors_annotated": len(sorted_colors),
                "processing_info": {
                    "original_size": f"{width}x{height}",
                    "final_size": f"{final_img_pil.width}x{final_img_pil.height}",
                    "layout": "right_side_annotation",
                    "features": ["color_blocks", "guide_lines", "sorted_by_proportion"]
                }
            }
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡æ ‡æ³¨å¤±è´¥: {str(e)}")
            return {"error": f"å›¾ç‰‡æ ‡æ³¨å¤±è´¥: {str(e)}"}
    
    @app.get("/nim/wcag-requirements")
    async def get_wcag_requirements():
        """è·å–WCAGè¦æ±‚"""
        try:
            nim_client = NIMClient()
            wcag_info = await nim_client.get_wcag_requirements()
            return wcag_info
            
        except Exception as e:
            return {"error": f"è·å–WCAGè¦æ±‚å¤±è´¥: {str(e)}"}
    
    @app.post("/chat")
    async def chat(message: dict):
        """èŠå¤©æ¥å£ï¼Œé›†æˆç™¾ç‚¼API"""
        from bailian_client import BailianClient
        
        try:
            user_message = message.get("message", "")
            if not user_message:
                return {"error": "è¯·è¾“å…¥æœ‰æ•ˆçš„æ¶ˆæ¯"}
            
            client = BailianClient()
            
            # ä½¿ç”¨å¢å¼ºèŠå¤©åŠŸèƒ½ï¼Œæ”¯æŒæ™ºèƒ½NIMè°ƒç”¨
            result = await client.enhanced_chat_completion(user_message)
            
            if result['success']:
                return {
                    "message": user_message,
                    "reply": result['content'],
                    "model": result.get('model', 'qwen-plus'),
                    "usage": result.get('usage', {}),
                    "timestamp": "2025-01-07T13:34:35+08:00"
                }
            else:
                return {
                    "error": result['error'],
                    "details": result.get('details', '')
                }
                
        except Exception as e:
            return {"error": f"æœåŠ¡é”™è¯¯: {str(e)}"}
    
    @app.post("/chat/stream")
    async def chat_stream(request: dict):
        """æµå¼èŠå¤©æ¥å£ï¼Œé›†æˆç™¾ç‚¼API"""
        from bailian_client import BailianClient
        
        async def generate_response():
            try:
                message = request.get("message", "")
                if not message:
                    yield f"data: {json.dumps({'choices': [{'delta': {'content': 'è¯·è¾“å…¥æœ‰æ•ˆçš„æ¶ˆæ¯'}, 'finish_reason': 'stop'}]})}\n\n"
                    return
                
                client = BailianClient()
                
                # ä½¿ç”¨å¢å¼ºæµå¼èŠå¤©åŠŸèƒ½ï¼Œæ”¯æŒæ™ºèƒ½NIMè°ƒç”¨
                async for chunk in client.enhanced_chat_stream(message):
                    if chunk['success']:
                        response_chunk = {
                            "choices": [{
                                "delta": {"content": chunk['content']},
                                "finish_reason": chunk.get('finish_reason')
                            }]
                        }
                        yield f"data: {json.dumps(response_chunk)}\n\n"
                        
                        if chunk.get('finish_reason') == 'stop':
                            break
                    else:
                        error_chunk = {
                            "choices": [{
                                "delta": {"content": f"é”™è¯¯: {chunk['error']}"},
                                "finish_reason": "stop"
                            }]
                        }
                        yield f"data: {json.dumps(error_chunk)}\n\n"
                        break
                        
            except Exception as e:
                error_chunk = {
                    "choices": [{
                        "delta": {"content": f"æœåŠ¡é”™è¯¯: {str(e)}"},
                        "finish_reason": "stop"
                    }]
                }
                yield f"data: {json.dumps(error_chunk)}\n\n"
                
        return StreamingResponse(
            generate_response(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache"}
        )
    
    @app.websocket("/websocket")
    async def websocket_endpoint(websocket: WebSocket):
        """WebSocketèŠå¤©æ¥å£"""
        await websocket.accept()
        try:
            while True:
                data = await websocket.receive_text()
                message_data = json.loads(data)
                user_message = message_data.get("message", "")
                
                # æ¨¡æ‹Ÿå“åº”
                response = {
                    "type": "message",
                    "content": f"WebSocketå›å¤ï¼š{user_message}",
                    "timestamp": "2025-01-07T11:21:55+08:00"
                }
                
                await websocket.send_text(json.dumps(response))
        except WebSocketDisconnect:
            pass
    
    return app

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ UI Color Bot å¿«é€Ÿå¯åŠ¨")
    print("=" * 30)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_env()
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("BAILIAN_API_KEY")
    if not api_key or api_key == "your_actual_api_key_here":
        print("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®çœŸå®çš„ç™¾ç‚¼APIå¯†é’¥")
        return
    
    print(f"âœ… ç™¾ç‚¼APIå¯†é’¥å·²é…ç½® (é•¿åº¦: {len(api_key)})")
    
    # åˆ›å»ºåº”ç”¨
    app = create_simple_app()
    
    print("\nğŸš€ å¯åŠ¨æœåŠ¡å™¨...")
    print("ğŸ“ è®¿é—®åœ°å€: http://localhost:8001")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:8001/docs")
    print("ğŸ›‘ åœæ­¢æœåŠ¡: æŒ‰ Ctrl+C")
    print("-" * 50)
    
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        reload=False
    )

if __name__ == "__main__":
    main()
